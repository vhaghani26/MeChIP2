#!/usr/bin/env python3
import argparse
import os
import re
import sys

def add_rule(path):
	with open(path) as fh:
		rule = fh.read()
		rule = rule.replace('PATH_TO_GENOME', arg.genome)
		rule = rule.replace('GENOME', genome_name)
		if 'samtools' in rule:
			rule = rule.replace('THREADS', str(arg.threads-1))
		else:
			rule = rule.replace('THREADS', str(arg.threads))
		
		if arg.peak_type == 'narrow':
			rule = rule.replace('PEPR_PEAK_TYPE','sharp')
			rule = rule.replace('MACS3_PEAK_TYPE','')
		elif arg.peak_type == 'broad':
			rule = rule.replace('PEPR_PEAK_TYPE','broad')
			rule = rule.replace('MACS3_PEAK_TYPE','--broad')
		
		if arg.read_type == 'se':
			rule = rule.replace('PEPR_READ_TYPE','bam')
			rule = rule.replace('GENRICH_READ_TYPE','-y')
			rule = rule.replace('MACS3_READ_TYPE','BAM')
		elif arg.read_type == 'pe':
			rule = rule.replace('PEPR_READ_TYPE','bampe')
			rule = rule.replace('GENRICH_READ_TYPE','')
			rule = rule.replace('MACS3_READ_TYPE','BAMPE')
		sf.write(f'{rule}\n')

parser = argparse.ArgumentParser(description='Make Snakefiles')
parser.add_argument('-o', '--output_file', type=str, metavar='<path>', required=True,
	help='output snakefile name')
parser.add_argument('-s', '--samples', type=str, metavar='<samples>', nargs='+',
	required=False, help='path to directory of sample fastq files or names/files of SRA identifiers')
parser.add_argument('-c', '--controls', type=str, metavar='<samples>', nargs='+',
	required=False, help='path to directory of control fastq files or names/files of SRA identifiers')
parser.add_argument('-g', '--genome', type=str, metavar='<str>', required=True,
	help='path to fasta file or name of remote genome (e.g. ~/mygenome.fa, sacCer3)')
parser.add_argument('-r', '--read_type', type=str, metavar='<str>', required=True,
	help='input [se] for single end reads or [pe] for paired end readers')
parser.add_argument('--config_file', type=str, metavar='<path>', required=True,
	help='path to yaml config file')
parser.add_argument('--threads', type=int, metavar='<int>', required=False,
	help='Enter number of threads [1]', default=1)
parser.add_argument('--peak_type', type=str, metavar='<str>', required=False,
	help='select peak type {narrow, broad} (default: narrow)', default='narrow')
parser.add_argument('--aligner', type=str, metavar='<str>', required=False,
	help='input sequence aligner {bwa_mem, bowtie2, STAR} (default: bwa_mem)',
	default='bwa_mem')
parser.add_argument('--peakcaller', type=str, metavar='<str>', required = False,
	help='input peak calling program {macs3, genrich, pepr, peakseq, cisgenome (default: macs3)', default='macs3')
parser.add_argument('--deduplicator', type=str, metavar='<str>', required=False,
	help='input deduplication tool {samtools, picard, sambamba, no_deduplication} (default: samtools)', 	
	default='samtools')
arg = parser.parse_args()

if arg.controls is None and arg.peakcaller == 'pepr':
	sys.stderr.write('Error: Pepr peakcaller must contain at least 1 control and '
		'2 sample replicates\n')
	sys.exit(1)

# extract genome name
genome_name = re.split('\.', re.split('/',arg.genome)[-1])[0]

sf = open(arg.output_file, 'w')

# config file
sf.write(f'configfile: \"{arg.config_file}\"\n\n')

# rule all: fastq files, peak files, bigwig file
if arg.controls:
	add_rule(f'rules/rule_all/fastq/fastq_with_control_{arg.read_type}.txt')
	add_rule(f'rules/rule_all/peaks/{arg.peakcaller}_with_control.txt')
else:
	add_rule(f'rules/rule_all/fastq/fastq_no_control_{arg.read_type}.txt')
	add_rule(f'rules/rule_all/peaks/{arg.peakcaller}_no_control.txt')
add_rule(f'rules/rule_all/bigwig/bigwig.txt')
	
# make directories
add_rule(f'rules/make_dir/make_dir.txt')

# download/link genome:
if os.path.isfile(arg.genome): add_rule(f'rules/get_genome/local_genome.txt')
else:						   add_rule(f'rules/get_genome/remote_genome.txt')	
		
# index genome:
add_rule(f'rules/index_genome/{arg.aligner}.txt')
	
# download/link fastq

# sra to fastq

# fastq preprocessing
add_rule(f'rules/fastqc/preprocessing_{arg.read_type}.txt')

# align reads
add_rule(f'rules/align_reads/{arg.aligner}_{arg.read_type}.txt')
	
# sort reads
add_rule(f'rules/sort_index_reads/samtools_sort.txt')

# markdup
if arg.deduplicator == 'no_deduplication':
	add_rule(f'rules/mark_dup/fake_dedup.txt')
else:
	add_rule(f'rules/mark_dup/{arg.deduplicator}_dedup.txt')

# index bam/sam
with open(f'rules/sort_index_reads/samtools_index.txt') as fh:
	rule = fh.read()
	rule = rule.replace('THREADS', str(arg.threads-1))
	sf.write(f'\n{rule}')
	
# bam to bigwig
add_rule(f'rules/bam_to_bigwig/bam_to_bigwig.txt')

# call peak
if arg.controls:
	add_rule(f'rules/call_peaks/{arg.peakcaller}/{arg.peakcaller}_with_control.txt')
else:
	add_rule(f'rules/call_peaks/{arg.peakcaller}/{arg.peakcaller}_no_control.txt')
