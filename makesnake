#!/usr/bin/env python3
import argparse
import os
import re

parser = argparse.ArgumentParser(description='Make Snakefiles')
parser.add_argument('-o', '--output_file', type=str, metavar='<path>', required=True,
	help='output filename')
parser.add_argument('-r', '--read_type', type=str, metavar='<str>', required=True,
	help='input [single] for single end reads or [paired] for paired end readers')
parser.add_argument('-g', '--reference_genome', type=str, metavar='<path>', required=True,
	help='input path to reference_genome (genome.fa)')
parser.add_argument('-i', '--index_genome', action = 'store_true',
	help='index the genome')
parser.add_argument('-c', '--config_file', type=str, metavar='<path>', required=True,
	help='path to yaml config file')
parser.add_argument('-a', '--aligner', type=str, metavar='<str>', required=False,
	help='input sequence aligner {bwa_mem, bowtie2, STAR} (default: bwa_mem)',
	default='bwa_mem')
parser.add_argument('-p', '--peakcaller', type=str, metavar='<str>', required = False,
	help='input peak calling program {macs2, macs3} (default: macs3)', default='macs3')
parser.add_argument('-d', '--deduplicator', type=str, metavar='<str>', required=False,
	help='input deduplication tool {samtools, umitools, sambamba, no_duplication} (default: samtools)', 	
	default='samtools')
arg = parser.parse_args()



genome_prefix = re.split('\.', re.split('/',arg.reference_genome)[-1])[0]

# index genome
if arg.index_genome:
	if arg.aligner == 'bwa_mem':
		os.system(f'bwa index -p {genome_prefix} -a bwtsw {arg.reference_genome}')
		os.system(f'mv {genome_prefix}* data/')
	elif arg.aligner == 'bowtie2':
		os.system(f'bowtie2-build {arg.reference_genome} data/{genome_prefix}')
	elif arg.aligner == 'STAR':
		os.system(f'STAR --runMode genomeGenerate --genomeDir data/genome --genomeFastaFiles {arg.reference_genome}')

sf = open(arg.output_file, 'w')

# config file
sf.write(f'configfile: \"{arg.config_file}\"\n\n')

# rule all
with open('rules/rule_all/rule_all.txt') as fh:
	rule_all = ''.join(fh.readlines())
	sf.write(f'{rule_all}\n')

# align reads
# need to add options for single or paired end reads
if arg.read_type == 'single':
	with open(f'rules/align_reads/{arg.aligner}_se.txt') as fh:
		align_rule = ''.join(fh.readlines())
		align_rule = re.sub('GENOME_PREFIX', genome_prefix, align_rule)
		sf.write(f'{align_rule}\n')
elif arg.read_type == 'paired':
	with open(f'rules/align_reads/{arg.aligner}_pe.txt') as fh:
		align_rule = ''.join(fh.readlines())
		align_rule = re.sub('GENOME_PREFIX', genome_prefix, align_rule)
		sf.write(f'{align_rule}\n')


# sort reads
with open(f'rules/sort_index_reads/samtools_sort.txt') as fh:
	samtools_sort = ''.join(fh.readlines())
	sf.write(f'{samtools_sort}\n')

# mark dup
if arg.deduplicator == 'no_duplication':
	with open(f'rules/mark_dup/fake_dedup.txt') as fh:
		dedup_rule = ''.join(fh.readlines())
		sf.write(f'{dedup_rule}\n')
else:
	with open(f'rules/mark_dup/{arg.deduplicator}_dedup.txt') as fh:
		dedup_rule = ''.join(fh.readlines())
		sf.write(f'{dedup_rule}\n')

# index reads
with open(f'rules/sort_index_reads/samtools_index.txt') as fh:
	samtools_index = ''.join(fh.readlines())
	sf.write(f'{samtools_index}\n')

# call_peaks
'''
--nomodel argument is included for the sake of testing fake data set generated
	using datasynth. Otherwise macs wouldn't run because it tries to look for
	paired +/- strand peaks which datasynth doesn't generate.
'''
with open(f'rules/call_peaks/{arg.peakcaller}.txt') as fh:
	callpeaks_rule = ''.join(fh.readlines())
	sf.write(f'{callpeaks_rule}\n')
	
# evaluate_peaks

sf.close()

