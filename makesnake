#!/usr/bin/env python3
import argparse
import os
import re

parser = argparse.ArgumentParser(description='Make Snakefiles')
parser.add_argument('-o', '--output_file', type=str, metavar='<path>', required=True,
	help='output filename')
parser.add_argument('-r', '--read_type', type=str, metavar='<str>', required=True,
	help='input [se] for single end reads or [pe] for paired end readers')
parser.add_argument('-g', '--reference_genome', type=str, metavar='<path>', required=True,
	help='input path to reference_genome (genome.fa)')
parser.add_argument('--config_file', type=str, metavar='<path>', required=True,
	help='path to yaml config file')
parser.add_argument('--index_genome', action='store_true',
	help='index the genome')
parser.add_argument('--threads', type=int, metavar='<int>', required=False,
	help='Enter number of threads [1]', default=1)
parser.add_argument('--broad', action = 'store_true',
	help='if set, the peak calling program will try to call board peaks')
parser.add_argument('--aligner', type=str, metavar='<str>', required=False,
	help='input sequence aligner {bwa_mem, bowtie2, STAR} (default: bwa_mem)',
	default='bwa_mem')
parser.add_argument('--peakcaller', type=str, metavar='<str>', required = False,
	help='input peak calling program {macs2, macs3} (default: macs3)', default='macs3')
parser.add_argument('--deduplicator', type=str, metavar='<str>', required=False,
	help='input deduplication tool {samtools, picard, sambamba, no_deduplication} (default: samtools)', 	
	default='samtools')
arg = parser.parse_args()



genome_prefix = re.split('\.', re.split('/',arg.reference_genome)[-1])[0]

# index genome
if arg.index_genome:
	if arg.aligner == 'bwa_mem':
		os.system(f'bwa index -p {genome_prefix} -a bwtsw {arg.reference_genome}')
		os.system(f'mv {genome_prefix}* data/')
	elif arg.aligner == 'bowtie2':
		os.system(f'bowtie2-build {arg.reference_genome} data/{genome_prefix}')
	elif arg.aligner == 'STAR':
		os.system(f'STAR --runMode genomeGenerate --genomeDir data/genome --genomeFastaFiles {arg.reference_genome}')

sf = open(arg.output_file, 'w')

# config file
sf.write(f'configfile: \"{arg.config_file}\"\n\n')

# rule all
with open('rules/rule_all/rule_all.txt') as fh:
	rule_all = ''.join(fh.readlines())
	sf.write(f'{rule_all}\n')

# fastq preprocessing
with open(f'rules/fastqc/preprocessing_{arg.read_type}') as fh:
	fastqc_rule = ''.join(fh.readlines())
	sf.write(f'{fastqc_rule}\n')

# align reads
# need to add options for single or paired end reads
with open(f'rules/align_reads/{arg.aligner}_{arg.read_type}.txt') as fh:
	align_rule = ''.join(fh.readlines())
	align_rule = re.sub('GENOME_PREFIX', genome_prefix, align_rule)
	align_rule = re.sub('THREADS', str(arg.threads), align_rule)
	sf.write(f'{align_rule}\n')


# sort reads
with open(f'rules/sort_index_reads/samtools_sort.txt') as fh:
	samtools_sort = ''.join(fh.readlines())
	samtools_sort = re.sub('THREADS', str(arg.threads-1), samtools_sort)
	sf.write(f'{samtools_sort}\n')

# mark dup
if arg.deduplicator == 'no_deduplication':
	with open(f'rules/mark_dup/fake_dedup.txt') as fh:
		dedup_rule = ''.join(fh.readlines())
		sf.write(f'{dedup_rule}\n')
else:
	with open(f'rules/mark_dup/{arg.deduplicator}_dedup.txt') as fh:
		dedup_rule = ''.join(fh.readlines())
		if arg.deduplicator == 'samtools':
			dedup_rule = re.sub('THREADS', str(arg.threads-1), dedup_rule)
		elif arg.deduplicator == 'sambamba':
			dedup_rule = re.sub('THREADS', str(arg.threads), dedup_rule)
		sf.write(f'{dedup_rule}\n')

# index reads
if arg.deduplicator != 'sambamba':
	with open(f'rules/sort_index_reads/samtools_index.txt') as fh:
		samtools_index = ''.join(fh.readlines())
		samtools_index = re.sub('THREADS', str(arg.threads-1), samtools_index)
		sf.write(f'{samtools_index}\n')
		
# bam to bigwig
with open(f'rules/bam_to_bigwig/bam_to_bigwig.txt') as fh:
	bigwig_rule = ''.join(fh.readlines())
	sf.write(f'{bigwig_rule}\n')

# call_peaks
'''
macs: --nomodel argument is included for the sake of testing fake data set generated
	using datasynth. Otherwise macs wouldn't run because it tries to look for
	paired +/- strand peaks which datasynth doesn't generate.
'''
with open(f'rules/call_peaks/{arg.peakcaller}_{arg.read_type}.txt') as fh:
	callpeaks_rule = ''.join(fh.readlines())
	if arg.peakcaller.startswith('macs'):
		if arg.broad: callpeaks_rule = re.sub('BROAD', '--broad', callpeaks_rule)
		else: callpeaks_rule = re.sub('BROAD', '', callpeaks_rule)
	sf.write(f'{callpeaks_rule}\n')

# fastq postprocessing
with open(f'rules/fastqc/postprocessing_{arg.read_type}') as fh:
	fastqc_rule = ''.join(fh.readlines())
	sf.write(f'{fastqc_rule}\n')

sf.close()

